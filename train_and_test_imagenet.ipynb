{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "SD8EvIMWEBPH",
    "outputId": "f582d519-eb7a-457f-9705-0d961fc032a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 24 08:36:20 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 49%   60C    P0    56W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 46%   59C    P0    70W / 250W |      0MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "| 37%   55C    P0    60W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 55%   61C    P0    33W / 250W |      0MiB / 11016MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuCAgoS1Hn4L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# For clean\\n\\nimport os\\nimport fnmatch\\n \\nINTERNAL_DATA_PATH = \\'cropped_coco/\\'\\n# Get a list of all files in directory\\nfor rootDir, subdirs, filenames in os.walk(INTERNAL_DATA_PATH):\\n    # Find the files that matches the given patterm\\n    for filename in fnmatch.filter(filenames, \\'.*\\'):\\n        try:\\n            #print(filename)\\n            os.remove(os.path.join(rootDir, filename))\\n        except OSError:\\n            print(\"Error while deleting file\")\\n    for subdir in fnmatch.filter(subdirs, \\'.*\\'):\\n        try:\\n            #print(filename)\\n            os.remove(os.path.join(rootDir, subdir))\\n        except OSError:\\n            print(\"Error while deleting file\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# For clean\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    " \n",
    "INTERNAL_DATA_PATH = 'cropped_coco/'\n",
    "# Get a list of all files in directory\n",
    "for rootDir, subdirs, filenames in os.walk(INTERNAL_DATA_PATH):\n",
    "    # Find the files that matches the given patterm\n",
    "    for filename in fnmatch.filter(filenames, '.*'):\n",
    "        try:\n",
    "            #print(filename)\n",
    "            os.remove(os.path.join(rootDir, filename))\n",
    "        except OSError:\n",
    "            print(\"Error while deleting file\")\n",
    "    for subdir in fnmatch.filter(subdirs, '.*'):\n",
    "        try:\n",
    "            #print(filename)\n",
    "            os.remove(os.path.join(rootDir, subdir))\n",
    "        except OSError:\n",
    "            print(\"Error while deleting file\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-52A9hHEf9y"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "########################################################################\n",
    "batch_size = 16\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'image'\n",
    "TRAIN_PATH = DATASET_PATH + '/train'\n",
    "TEST_PATH = DATASET_PATH + '/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_size = [729,243,81,27,9]  \n",
    "\n",
    "default_transform = transforms.Compose(\n",
    "    [transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainImageNetDataset = datasets.ImageFolder(root=TRAIN_PATH,transform = default_transform)\n",
    "testImageNetDataset = datasets.ImageFolder(root=TEST_PATH,transform = default_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainImageNetDataset,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle=True,\n",
    "                                         num_workers=4)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testImageNetDataset,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle=False,\n",
    "                                        num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5004.5625"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCResnet import SCResNet50,ResNet50\n",
    "from torchvision.models import resnet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "os.environ['MASTER_PORT'] = '29500'\n",
    "dist.init_process_group(backend='nccl',rank=0,world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "xdajs104otKK",
    "outputId": "294463e8-ed55-49c4-939e-6bdda6c87d72"
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "num_classes = 1000\n",
    "#model1 = resnet50(num_classes=num_classes).to(device)\n",
    "model1 = SCResNet50(num_classes).to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model1 = DDP(model1,device_ids = [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74xBqeGcpub_"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RESULT_PATH = 'testresults/'\n",
    "WEIGHTS_PATH = 'weights/'\n",
    "\n",
    "TASK_NAME = 'ImageNet_SCResnet_50'\n",
    "DATE = 'apr24'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Pd0stQ4Jolv7",
    "outputId": "3e1b592d-71a2-41cf-9936-8dd874e59431",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/nfs/home/hama2386/.local/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "290it [03:27,  1.36it/s]"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import sys\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "acc_list = []\n",
    "acc_list_aug = []\n",
    "num_batches = len(trainloader)\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    model1.train()\n",
    "    for i,images in tqdm(enumerate(trainloader)):\n",
    "        optimizer.zero_grad()\n",
    "        c1 = images[0].to(device)\n",
    "        c6 = images[1].to(device)\n",
    "        output = model1(c1)\n",
    "        loss = criterion(output, c6)\n",
    "        loss.backward()    # calc gradients\n",
    "        optimizer.step()   # update gradients\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model1.eval()\n",
    "    with torch.no_grad(): # very very very very important!!!\n",
    "        val_loss = 0.0\n",
    "        class_correct = list(0. for i in range(num_classes))\n",
    "        class_total = list(0. for i in range(num_classes))\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for j,val in enumerate(testloader):\n",
    "            v1 = val[0].to(device)\n",
    "            val_labels = val[1].to(device)\n",
    "            val_output = model1(v1)\n",
    "            v_loss = criterion(val_output, val_labels)\n",
    "            val_loss += v_loss\n",
    "            _, predicted = torch.max(val_output, 1)\n",
    "            c = (predicted == val_labels).squeeze()\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels).sum().item()\n",
    "            for i in range(len(val_labels)):\n",
    "                val_label = val_labels[i]\n",
    "                class_correct[val_label] += c[i].item()\n",
    "                class_total[val_label] += 1\n",
    "\n",
    "        print(\"epoch:\",str(epoch),str(i),\" batch\")\n",
    "        temp_acc = []\n",
    "        for i in range(num_classes):\n",
    "            if class_total[i]==0:\n",
    "                print('class_total = 0',class_correct,class_total)\n",
    "            else:\n",
    "                print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))\n",
    "                temp_acc.append(100 * class_correct[i] / class_total[i])\n",
    "        acc_list.append(temp_acc)\n",
    "\n",
    "    print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "        epoch+1, 20, i+1, num_batches, running_loss / len(trainloader), val_loss / len(testloader)\n",
    "    ))        \n",
    "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "    trn_loss_list.append(running_loss/1875)\n",
    "    val_loss_list.append(val_loss/len(testloader))\n",
    "    running_loss = 0.0\n",
    "\n",
    "    import csv\n",
    "\n",
    "    csvfile = open(TEST_RESULT_PATH+'testresult_'+TASK_NAME+'_'+DATE+'.csv','w',newline=\"\")\n",
    "\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    for row in acc_list:\n",
    "        csvwriter.writerow(row)\n",
    "\n",
    "    csvfile.close()\n",
    "\n",
    "    torch.save(model1.state_dict(),WEIGHTS_PATH+TASK_NAME+'_'+DATE+'.pt')\n",
    "\n",
    "    model1.train()\n",
    "    if epoch == 9:\n",
    "        optimizer = optim.Adam(model1.parameters(), lr=0.0001)\n",
    "        print('lr is changed to 0.0001')\n",
    "        \n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST ENDS\n",
    "code below won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SC_CNN_v0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
