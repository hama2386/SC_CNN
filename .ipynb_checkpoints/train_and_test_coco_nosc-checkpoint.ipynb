{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "SD8EvIMWEBPH",
    "outputId": "f582d519-eb7a-457f-9705-0d961fc032a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar 31 15:59:59 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 44%   58C    P0    54W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 42%   57C    P0    69W / 250W |      0MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "| 33%   53C    P0    59W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 50%   59C    P0    30W / 250W |      0MiB / 11016MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuCAgoS1Hn4L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# For clean\\n\\nimport os\\nimport fnmatch\\n \\nINTERNAL_DATA_PATH = \\'cropped_coco/\\'\\n# Get a list of all files in directory\\nfor rootDir, subdirs, filenames in os.walk(INTERNAL_DATA_PATH):\\n    # Find the files that matches the given patterm\\n    for filename in fnmatch.filter(filenames, \\'.*\\'):\\n        try:\\n            #print(filename)\\n            os.remove(os.path.join(rootDir, filename))\\n        except OSError:\\n            print(\"Error while deleting file\")\\n    for subdir in fnmatch.filter(subdirs, \\'.*\\'):\\n        try:\\n            #print(filename)\\n            os.remove(os.path.join(rootDir, subdir))\\n        except OSError:\\n            print(\"Error while deleting file\")'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# For clean\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    " \n",
    "INTERNAL_DATA_PATH = 'cropped_coco/'\n",
    "# Get a list of all files in directory\n",
    "for rootDir, subdirs, filenames in os.walk(INTERNAL_DATA_PATH):\n",
    "    # Find the files that matches the given patterm\n",
    "    for filename in fnmatch.filter(filenames, '.*'):\n",
    "        try:\n",
    "            #print(filename)\n",
    "            os.remove(os.path.join(rootDir, filename))\n",
    "        except OSError:\n",
    "            print(\"Error while deleting file\")\n",
    "    for subdir in fnmatch.filter(subdirs, '.*'):\n",
    "        try:\n",
    "            #print(filename)\n",
    "            os.remove(os.path.join(rootDir, subdir))\n",
    "        except OSError:\n",
    "            print(\"Error while deleting file\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-52A9hHEf9y"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "########################################################################\n",
    "batch_size = 16\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'cropped_coco'\n",
    "TRAIN_PATH = DATASET_PATH + '/train/50'\n",
    "TEST_PATH = DATASET_PATH + '/val/50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_size = [729,243,81,27,9]  \n",
    "\n",
    "default_transform = transforms.Compose(\n",
    "    [transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "trainCocoDataset = datasets.ImageFolder(root=TRAIN_PATH,transform = default_transform)\n",
    "testCocoDataset = datasets.ImageFolder(root=TEST_PATH,transform = default_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainCocoDataset,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle=True,\n",
    "                                         num_workers=4)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testCocoDataset,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle=False,\n",
    "                                        num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trainCocoDataset.class_to_idx'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''trainCocoDataset.class_to_idx'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SCResnet import SCResNet50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "os.environ['MASTER_PORT'] = '29500'\n",
    "dist.init_process_group(backend='nccl',rank=0,world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "xdajs104otKK",
    "outputId": "294463e8-ed55-49c4-939e-6bdda6c87d72"
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "model1 = SCResNet50(80).to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model1 = DDP(model1,device_ids = [0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  7.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "\n",
    "SIZED_VAL_PATH = 'cropped_coco/val'\n",
    "\n",
    "val_gen_arr = []\n",
    "for i in tqdm(range(10,110,10)):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "    testCocoDataset_val = datasets.ImageFolder(root=os.path.join(SIZED_VAL_PATH,str(i)),transform = transform)\n",
    "\n",
    "    testloader_val = torch.utils.data.DataLoader(testCocoDataset_val,\n",
    "                                              batch_size = batch_size, \n",
    "                                              shuffle=False,\n",
    "                                            num_workers=4)\n",
    "    val_gen_arr.append(testloader_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74xBqeGcpub_"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RESULT_PATH = 'testresults/'\n",
    "WEIGHTS_PATH = 'weights/'\n",
    "\n",
    "TASK_NAME = 'COCO_SCResnet_50'\n",
    "DATE = 'mar30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Pd0stQ4Jolv7",
    "outputId": "3e1b592d-71a2-41cf-9936-8dd874e59431",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import sys\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "acc_list = []\n",
    "acc_list_aug = []\n",
    "num_batches = len(trainloader)\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    model1.train()\n",
    "    device = 'cuda:0'\n",
    "    for i,images in tqdm(enumerate(trainloader)):\n",
    "        optimizer.zero_grad()\n",
    "        c1 = images[0].to(device)\n",
    "        c6 = images[1].to(device)\n",
    "        output = model1(c1)\n",
    "        loss = criterion(output, c6)\n",
    "        loss.backward()    # calc gradients\n",
    "        optimizer.step()   # update gradients\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "        if (i+1) % 25000 == 0:\n",
    "            model1.eval()\n",
    "            with torch.no_grad(): # very very very very important!!!\n",
    "                val_loss = 0.0\n",
    "                class_correct = list(0. for i in range(80))\n",
    "                class_total = list(0. for i in range(80))\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                for j,val in enumerate(testloader):\n",
    "                    v1 = val[0].to(device)\n",
    "                    val_labels = val[1].to(device)\n",
    "                    val_output = model1(v1)\n",
    "                    v_loss = criterion(val_output, val_labels)\n",
    "                    val_loss += v_loss\n",
    "                    _, predicted = torch.max(val_output, 1)\n",
    "                    c = (predicted == val_labels).squeeze()\n",
    "                    total += val_labels.size(0)\n",
    "                    correct += (predicted == val_labels).sum().item()\n",
    "                    for i in range(len(val_labels)):\n",
    "                        val_label = val_labels[i]\n",
    "                        class_correct[val_label] += c[i].item()\n",
    "                        class_total[val_label] += 1\n",
    "\n",
    "                print(\"epoch:\",str(epoch),str(i),\" batch\")\n",
    "                for i in range(80):\n",
    "                    if class_total[i]==0:\n",
    "                        print('class_total = 0',class_correct,class_total)\n",
    "                    else:\n",
    "                        print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "            print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "                epoch+1, 20, i+1, num_batches, running_loss / len(trainloader), val_loss / len(testloader)\n",
    "            ))        \n",
    "            print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "            trn_loss_list.append(running_loss/1875)\n",
    "            val_loss_list.append(val_loss/len(testloader))\n",
    "            running_loss = 0.0\n",
    "\n",
    "            temp_acc = []\n",
    "            for testloader_val in tqdm(val_gen_arr):\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                class_correct = list(0. for i in range(80))\n",
    "                class_total = list(0. for i in range(80))\n",
    "                with torch.no_grad():\n",
    "                    for images in testloader_val:\n",
    "                        c1 = images[0].to(device)\n",
    "                        val_labels = images[1].to(device)\n",
    "                        outputs = model1(c1)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        c = (predicted == val_labels).squeeze()\n",
    "                        total += val_labels.size(0)\n",
    "                        correct += (predicted == val_labels).sum().item()\n",
    "                #print(total,correct,end='')\n",
    "\n",
    "                print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "                temp_acc.append(100 * correct / total)\n",
    "                #print(temp_acc)\n",
    "            acc_list.append(temp_acc)\n",
    "\n",
    "            import csv\n",
    "\n",
    "            csvfile = open(TEST_RESULT_PATH+'testresult_'+TASK_NAME+'_'+DATE+'.csv','w',newline=\"\")\n",
    "\n",
    "            csvwriter = csv.writer(csvfile)\n",
    "            for row in acc_list:\n",
    "                csvwriter.writerow(row)\n",
    "\n",
    "            csvfile.close()\n",
    "\n",
    "            torch.save(model1.state_dict(),WEIGHTS_PATH+TASK_NAME+'_'+DATE+'.pt')\n",
    "\n",
    "            model1.train()\n",
    "            \n",
    "    model1.eval()\n",
    "    with torch.no_grad(): # very very very very important!!!\n",
    "        val_loss = 0.0\n",
    "        class_correct = list(0. for i in range(80))\n",
    "        class_total = list(0. for i in range(80))\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for j,val in enumerate(testloader):\n",
    "            v1 = val[0].to(device)\n",
    "            val_labels = val[1].to(device)\n",
    "            val_output = model1(v1)\n",
    "            v_loss = criterion(val_output, val_labels)\n",
    "            val_loss += v_loss\n",
    "            _, predicted = torch.max(val_output, 1)\n",
    "            c = (predicted == val_labels).squeeze()\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels).sum().item()\n",
    "            for i in range(len(val_labels)):\n",
    "                val_label = val_labels[i]\n",
    "                class_correct[val_label] += c[i].item()\n",
    "                class_total[val_label] += 1\n",
    "\n",
    "        print(\"epoch:\",str(epoch),str(i),\" batch\")\n",
    "        for i in range(80):\n",
    "            if class_total[i]==0:\n",
    "                print('class_total = 0',class_correct,class_total)\n",
    "            else:\n",
    "                print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "        epoch+1, 20, i+1, num_batches, running_loss / len(trainloader), val_loss / len(testloader)\n",
    "    ))        \n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "    trn_loss_list.append(running_loss/1875)\n",
    "    val_loss_list.append(val_loss/len(testloader))\n",
    "    running_loss = 0.0\n",
    "\n",
    "    temp_acc = []\n",
    "    for testloader_val in tqdm(val_gen_arr):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        class_correct = list(0. for i in range(80))\n",
    "        class_total = list(0. for i in range(80))\n",
    "        with torch.no_grad():\n",
    "            for images in testloader_val:\n",
    "                c1 = images[0].to(device)\n",
    "                val_labels = images[1].to(device)\n",
    "                outputs = model1(c1)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                c = (predicted == val_labels).squeeze()\n",
    "                total += val_labels.size(0)\n",
    "                correct += (predicted == val_labels).sum().item()\n",
    "        #print(total,correct,end='')\n",
    "\n",
    "        print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "        temp_acc.append(100 * correct / total)\n",
    "        #print(temp_acc)\n",
    "    acc_list.append(temp_acc)\n",
    "\n",
    "    import csv\n",
    "\n",
    "    csvfile = open(TEST_RESULT_PATH+'testresult_'+TASK_NAME+'_'+DATE+'.csv','w',newline=\"\")\n",
    "\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    for row in acc_list:\n",
    "        csvwriter.writerow(row)\n",
    "\n",
    "    csvfile.close()\n",
    "\n",
    "    torch.save(model1.state_dict(),WEIGHTS_PATH+TASK_NAME+'_'+DATE+'.pt')\n",
    "\n",
    "    model1.train()\n",
    "    '''if epoch == 9:\n",
    "        optimizer = optim.Adam(model1.parameters(), lr=0.0001)\n",
    "        print('lr is changed to 0.0001')'''\n",
    "        \n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,images in tqdm(enumerate(trainloader)):\n",
    "    print(images[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND TEST ENDS\n",
    "code below won't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        \n",
    "        self.prepool1 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.prepool2 = nn.AvgPool2d(2,2)\n",
    "        \n",
    "        #self.sc1 = SCModule1(3,64)\n",
    "        self.rp1 = ResPoolModule(256)\n",
    "        self.rp2 = ResPoolModule(512)\n",
    "        self.rp3 = ResPoolModule(1024)\n",
    "        self.rp4 = ResPoolModule(2048)\n",
    "        \n",
    "        #self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        self.conv2_1 = SCBottleneck(64,256,downsample=True)\n",
    "        self.conv2_2 = SCBottleneck(256,256)\n",
    "        self.conv2_3 = SCBottleneck(256,256)\n",
    "        \n",
    "        self.conv3_1 = SCBottleneck(256,512,downsample=True)\n",
    "        self.conv3_2 = SCBottleneck(512,512)\n",
    "        self.conv3_3 = SCBottleneck(512,512)\n",
    "        self.conv3_4 = SCBottleneck(512,512)\n",
    "        \n",
    "        self.conv4_1 = SCBottleneck(512,1024,downsample=True)\n",
    "        self.conv4_2 = SCBottleneck(1024,1024)\n",
    "        self.conv4_3 = SCBottleneck(1024,1024)\n",
    "        self.conv4_4 = SCBottleneck(1024,1024)\n",
    "        self.conv4_5 = SCBottleneck(1024,1024)\n",
    "        self.conv4_6 = SCBottleneck(1024,1024)\n",
    "        \n",
    "        self.conv5_1 = SCBottleneck(1024,2048,downsample=True)\n",
    "        self.conv5_2 = SCBottleneck(2048,2048)\n",
    "        self.conv5_3 = SCBottleneck(2048,2048)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(2048,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        save = []\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        save.append(x)\n",
    "        \n",
    "        #print(x.size())\n",
    "            \n",
    "        x = self.conv2_1([self.prepool1(x),x,self.prepool2(x)])\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv2_2(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv2_3(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        \n",
    "        x = self.rp1(x)\n",
    "        save.append(x)\n",
    "        \n",
    "        #print(x.size())\n",
    "        \n",
    "        x = self.conv3_1([self.prepool1(x),x,self.prepool2(x)])\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv3_2(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv3_3(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv3_4(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        \n",
    "        x = self.rp2(x)\n",
    "        save.append(x)\n",
    "        \n",
    "        x = self.conv4_1([self.prepool1(x),x,self.prepool2(x)])\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv4_2(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv4_3(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv4_4(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv4_5(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv4_6(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        \n",
    "        x = self.rp3(x)\n",
    "        save.append(x)\n",
    "        \n",
    "        x = self.conv5_1([self.prepool1(x),x,self.prepool2(x)])\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv5_2(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        x = self.conv5_3(x)\n",
    "        save.append(x[0])\n",
    "        save.append(x[1])\n",
    "        save.append(x[2])\n",
    "        \n",
    "        x = self.rp4(x)\n",
    "        save.append(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x,save\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Net().to('cuda:0')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model1 = DDP(model1,device_ids = [0])\n",
    "'''    \n",
    "model2 = Net().to('cuda:0')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model2 = DDP(model2,device_ids = [2])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load_state_dict(torch.load('ResNet50_allsc_half_mar11.pt'))\n",
    "#model2.load_state_dict(torch.load('ResNet50_scrp2_feb19.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "#model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))])\n",
    "\n",
    "SIZED_VAL_PATH = 'mnist_sized'\n",
    "l2_img_test_arr = []\n",
    "for i in range(1,113):\n",
    "    img_path = os.path.join(SIZED_VAL_PATH,str(i),'9','1622.png')\n",
    "    img = Image.open(img_path)\n",
    "    img = transform(img)\n",
    "    img = torch.unsqueeze(img,0)\n",
    "    img.to(device)\n",
    "    l2_img_test_arr.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir res50_allsc_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = ['1st conv',\\\n",
    "        'sc2_1_1(256)','sc2_1_2(256)','sc2_1_3(256)',\\\n",
    "        'sc2_2_1(256)','sc2_2_2(256)','sc2_2_3(256)',\\\n",
    "        'sc2_3_1(256)','sc2_3_2(256)','sc2_3_3(256)',\\\n",
    "        'rp2',\\\n",
    "        'sc3_1_1(512)','sc3_1_2(512)','sc3_1_3(512)',\\\n",
    "        'sc3_2_1(512)','sc3_2_2(512)','sc3_2_3(512)',\\\n",
    "        'sc3_3_1(512)','sc3_3_2(512)','sc3_3_3(512)',\\\n",
    "        'sc3_4_1(512)','sc3_4_2(512)','sc3_4_3(512)',\\\n",
    "        'rp3',\\\n",
    "        'sc4_1_1(1024)','sc4_1_2(1024)','sc4_1_3(1024)',\\\n",
    "        'sc4_2_1(1024)','sc4_2_2(1024)','sc4_2_3(1024)',\\\n",
    "        'sc4_3_1(1024)','sc4_3_2(1024)','sc4_3_3(1024)',\\\n",
    "        'sc4_4_1(1024)','sc4_4_2(1024)','sc4_4_3(1024)',\\\n",
    "        'sc4_5_1(1024)','sc4_5_2(1024)','sc4_5_3(1024)',\\\n",
    "        'sc4_6_1(1024)','sc4_6_2(1024)','sc4_6_3(1024)',\\\n",
    "        'rp4',\\\n",
    "        'sc5_1_1(2048)','sc5_1_2(2048)','sc5_1_3(2048)',\\\n",
    "        'sc5_2_1(2048)','sc5_2_2(2048)','sc5_2_3(2048)',\\\n",
    "        'sc5_3_1(2048)','sc5_3_2(2048)','sc5_3_3(2048)',\\\n",
    "        'rp5']\n",
    "\n",
    "size = 1\n",
    "for img in tqdm(l2_img_test_arr):\n",
    "    with torch.no_grad():\n",
    "        outputs,save = model1(img)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    print(predicted)\n",
    "    \n",
    "    j = 0\n",
    "    plt.figure(figsize=(24,12))\n",
    "    plt.suptitle('resnet L2ALL SC half image size:'+str(size)+'\\n'+'predicted :'+str(predicted.cpu().numpy()[0])+' ground truth:9')\n",
    "    #plt.suptitle('resnet L2 ALL layer SC half')\n",
    "    for act in save:\n",
    "        dist = []\n",
    "        index = np.arange(act[0].size()[0])\n",
    "        for i in range(act[0].size()[0]):\n",
    "            dist.append(torch.norm(act[0][i],p=2).cpu().detach().numpy())\n",
    "        plt.subplot(6,9,j+1)\n",
    "        plt.title(name[j])\n",
    "        plt.bar(index,dist)\n",
    "        j = j+1\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "    plt.savefig('res50_allsc_l2/l2_'+str(size)+'.png')\n",
    "    plt.show()\n",
    "    size = size+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "frame_array = []\n",
    "for i in range(1,113):\n",
    "    filename='res50_allsc_l2/l2_'+str(i)+'.png'\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    #inserting the frames into an image array\n",
    "    frame_array.append(img)\n",
    "    \n",
    "out = cv2.VideoWriter('res50_allsc_l2/allsc_half_l2_mar15.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 5, size)\n",
    "for i in range(len(frame_array)):\n",
    "    # writing to a image array\n",
    "    out.write(frame_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.detach().numpy()\n",
    "    #plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    return np.transpose(npimg, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "def show_gradient(gradient):\n",
    "    #gradient = gradient.cpu().numpy().transpose(1, 2, 0)\n",
    "    gradient = gradient.cpu().numpy().transpose(1,2,0)\n",
    "    gradient -= gradient.min()\n",
    "    gradient /= gradient.max()\n",
    "    gradient *= 255.0\n",
    "    plt.imshow(np.squeeze(np.uint8(gradient),axis=2))\n",
    "    plt.show()\n",
    "\n",
    "def show_gradcam(gcam, raw_image, paper_cmap=False,show = True):\n",
    "    gcam = gcam.cpu().numpy()\n",
    "    cmap = cm.jet(gcam)[..., :3]*255.0#\n",
    "    if paper_cmap:\n",
    "        alpha = gcam[..., None]\n",
    "        gcam = alpha * cmap + (1 - alpha) * raw_image\n",
    "    else:\n",
    "        gcam = (cmap.astype(np.float) + raw_image.astype(np.float)) / 2\n",
    "        #gcam = (cmap.astype(np.float)*raw_image.astype(np.float))\n",
    "    if show:\n",
    "        plt.imshow(gcam.astype(np.uint8))\n",
    "        plt.show()\n",
    "        return 0\n",
    "    else:\n",
    "        return gcam.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir 'gradcam_2x_respool_soloconv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = []\n",
    "\n",
    "temp_acc = []\n",
    "device = 'cuda:0'\n",
    "for testloader in tqdm(val_gen_arr):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    confusion.append([])\n",
    "    with torch.no_grad():\n",
    "        for images in testloader:\n",
    "            c1 = images[0].to(device)\n",
    "            val_labels = images[1].to(device)\n",
    "            outputs = model1(c1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            #print(predicted)\n",
    "            c = (predicted == val_labels).squeeze()\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels).sum().item()\n",
    "            \n",
    "            confusion[-1].append(confusion_matrix(val_labels.cpu().numpy(),predicted.cpu().numpy(),labels=[0,1,2,3,4,5,6,7,8,9]))\n",
    "    #print(total,correct,end='')\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "    temp_acc.append(100 * correct / total)\n",
    "    \n",
    "#print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_sum = []\n",
    "\n",
    "for i in range(len(confusion)):\n",
    "    confusion_sum.append(confusion[i][0])\n",
    "    for j in range(1,len(confusion[i])):\n",
    "        confusion_sum[i] += confusion[i][j]\n",
    "        \n",
    "print(confusion_sum[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir confusion_2x_respool_soloconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in range(0,112):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    pred_name = ['pred '+str(x) for x in range(0,10)]\n",
    "    actual_name = ['true '+str(x) for x in range(0,10)]\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(confusion_sum[size],cmap = plt.cm.Greens)\n",
    "    fig.colorbar(cax)\n",
    "    ticks = np.arange(0,10,1)\n",
    "\n",
    "    ind_array = np.arange(0, 10, 1)\n",
    "    x, y = np.meshgrid(ind_array, ind_array)\n",
    "\n",
    "    for x_val, y_val in zip(x.flatten(), y.flatten()):\n",
    "        c = str(confusion_sum[size][y_val][x_val])\n",
    "        ax.text(x_val, y_val, c, va='center', ha='center')\n",
    "\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(pred_name)\n",
    "    ax.set_yticklabels(actual_name)\n",
    "    ax.set_title('size : '+str(size+1)+' acc : '+str(temp_acc[size]))\n",
    "    #plt.matshow(confusion_sum[0])\n",
    "    plt.savefig('confusion_2x_respool_soloconv/confusion'+str(size)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "frame_array = []\n",
    "for i in range(0,112):\n",
    "    filename='confusion_2x_respool_soloconv/confusion' + str(i)+'.png'\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    #inserting the frames into an image array\n",
    "    frame_array.append(img)\n",
    "    \n",
    "out = cv2.VideoWriter('confusion_2x_respool_soloconv/confusion_feb13.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 5, size)\n",
    "for i in range(len(frame_array)):\n",
    "    # writing to a image array\n",
    "    out.write(frame_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "SIZED_VAL_PATH = 'mnist_sized'\n",
    "new_path = []\n",
    "for i in range(1,113):\n",
    "    new_path.append([os.path.join(SIZED_VAL_PATH,str(i))])\n",
    "\n",
    "#new_path.sort(key=lambda x:int(x[0].split('/')[1]))\n",
    "\n",
    "gradcam_gen_arr = []\n",
    "for i in tqdm(range(0,len(new_path))):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307, 0.1307, 0.1307), (0.3081, 0.3081, 0.3081))])\n",
    "\n",
    "    testMnistDataset = SizedMnistDataset(new_path[i],transform)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testMnistDataset,\n",
    "                                              batch_size = batch_size, \n",
    "                                              shuffle=False,\n",
    "                                            num_workers=8)\n",
    "    gradcam_gen_arr.append(testloader)\n",
    "#\n",
    "#val_gen_arr\n",
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradcam import GradCAM\n",
    "from gradcam import GuidedBackPropagation\n",
    "\n",
    "#model1.eval()\n",
    "#model2.eval()\n",
    "gcam = GradCAM(model=model1)\n",
    "gbp = GuidedBackPropagation(model=model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in model1.named_modules():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gcam.fmap_pool.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "gridspec.GridSpec(3,6)\n",
    "\n",
    "imsize = 1\n",
    "for testloader in tqdm(gradcam_gen_arr):\n",
    "    for images in testloader:\n",
    "        v1 = images[0].to(device)\n",
    "        val_labels = images[1].to(device)\n",
    "        break\n",
    "\n",
    "    _ = gcam.forward(v1)\n",
    "    probs,ids = gbp.forward(v1)\n",
    "\n",
    "    gcam.backward(ids=ids[:,[0]])\n",
    "    gbp.backward(ids=ids[:,[0]])\n",
    "\n",
    "    grad_img = []\n",
    "\n",
    "    for j in range(len(v1)):\n",
    "        grad_img.append([])\n",
    "        for name, module in model1.named_modules():\n",
    "            #print(name)\n",
    "            if name == '' or name == 'module' or name == 'module.fc1' or name == 'module.fc2' or name == 'module.fc3' or name == 'module.prepool1' or name == 'module.prepool2':\n",
    "                continue\n",
    "            regions = gcam.generate(target_layer=name)\n",
    "            gradients = gbp.generate()\n",
    "            #print(\"\\t#{}: {} ({:.5f})\".format(j, ids[j, 0], probs[j, 0]))\n",
    "            #print(regions[j,0])\n",
    "            if name == 'module.sc1' or name == 'module.sc2' or name == 'module.sc3':\n",
    "                grad_img[j].append(show_gradcam(gcam=regions[0][j,0],raw_image=imshow(v1[j].cpu()),show=False))\n",
    "                grad_img[j].append(show_gradcam(gcam=regions[1][j,0],raw_image=imshow(v1[j].cpu()),show=False))\n",
    "                grad_img[j].append(show_gradcam(gcam=regions[2][j,0],raw_image=imshow(v1[j].cpu()),show=False))\n",
    "            if name == 'module.rp1':\n",
    "                grad_img[j].append(show_gradcam(gcam=regions[j,0],raw_image=imshow(v1[j].cpu()),show=False))\n",
    "\n",
    "    img_num = [0,1,2,3,4,5,15,16,17,18,19,20,31,32,33,34]\n",
    "    col_num = [3,3,3,1]\n",
    "    title = ['sc1 (L1,L2,L3)','sc2(L1,L2,L3)','sc3(L1,L2,L3)','rp1']\n",
    "    size = 112\n",
    "    \n",
    "    scale = 3./size\n",
    "    plt.figure(figsize=(18,9))\n",
    "    plt.suptitle('SC_CNN_2x_respool_gradcam'+'_size:'+str(imsize)+'_acc:'+str(temp_acc[imsize-1])+'\\n predicted:{} ({:.5f})'.format(ids[0, 0], probs[0, 0]))\n",
    "    num = 0\n",
    "    for i in range(len(col_num)):\n",
    "        display_grid = np.zeros((112,112*col_num[i],3)).astype(np.uint8)\n",
    "        for row in range(col_num[i]):\n",
    "            display_grid[:size,row*size : (row+1)*size,:3] = grad_img[0][num]\n",
    "            num = num+1\n",
    "        if i == 3:\n",
    "            plt.subplot2grid((3,6), (i//2,(i%2)*3),colspan = 1,rowspan=1)\n",
    "        else:\n",
    "            plt.subplot2grid((3,6), (i//2,(i%2)*3),colspan = 3,rowspan=1)\n",
    "        plt.axis('off')\n",
    "        plt.title(title[i])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid,aspect='auto')\n",
    "    plt.savefig('gradcam_2x_respool/pltgrad'+str(imsize)+'.png')\n",
    "    plt.show()\n",
    "    imsize = imsize+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_array = []\n",
    "for i in range(1,113):\n",
    "    filename='gradcam_2x/pltgrad' + str(i)+'.png'\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    \n",
    "    #inserting the frames into an image array\n",
    "    frame_array.append(img)\n",
    "    \n",
    "out = cv2.VideoWriter('gradcam_2x_respool/gradcam_ordered_feb13.mp4',cv2.VideoWriter_fourcc(*'MP4V'), 5, size)\n",
    "for i in range(len(frame_array)):\n",
    "    # writing to a image array\n",
    "    out.write(frame_array[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gcam.fmap_pool.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=0\n",
    "\n",
    "#plt.figure(figsize=(12,5))\n",
    "plt.matshow([gcam.fmap_pool['module.fc1'].cpu().numpy()[num]])\n",
    "plt.matshow([gcam.fmap_pool['module.fc2'].cpu().numpy()[num]])\n",
    "plt.matshow([gcam.fmap_pool['module.fc3'].cpu().numpy()[num]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "print(gcam.fmap_pool['module.prepool1'].cpu().numpy()[0][i].var())\n",
    "plt.imshow(gcam.fmap_pool['module.prepool2'].cpu().numpy()[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcam.fmap_pool['module.sc1_1'].cpu().numpy()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "#print(gcam.fmap_pool['module.sc1_1'].cpu().numpy()[0][num])\n",
    "plt.figure(figsize=(16,12))\n",
    "for i in range(6):\n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.imshow(gcam.fmap_pool['module.sc1_1'].cpu().numpy()[0][i])\n",
    "for i in range(6):\n",
    "    plt.subplot(3,6,i+1+6)\n",
    "    plt.imshow(gcam.fmap_pool['module.sc1_2'].cpu().numpy()[0][i])\n",
    "for i in range(6):\n",
    "    plt.subplot(3,6,i+1+12)\n",
    "    plt.imshow(gcam.fmap_pool['module.sc1_3'].cpu().numpy()[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "#print(gcam.fmap_pool['module.sc1_1'].cpu().numpy()[0][num])\n",
    "plt.figure(figsize=(16,5))\n",
    "for i in range(18):\n",
    "    plt.subplot(3,18,i+1)\n",
    "    plt.imshow(gcam.fmap_pool['module.sc2_1'].cpu().numpy()[0][i])\n",
    "for i in range(18):\n",
    "    plt.subplot(3,18,i+1+18)\n",
    "    plt.imshow(gcam.fmap_pool['module.sc2_2'].cpu().numpy()[0][i])\n",
    "for i in range(18):\n",
    "    plt.subplot(3,18,i+1+36)\n",
    "    plt.imshow(gcam.fmap_pool['module.sc2_3'].cpu().numpy()[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "#print(gcam.fmap_pool['module.sc1_1'].cpu().numpy()[0][num])\n",
    "plt.figure(figsize=(16,5))\n",
    "for i in range(30):\n",
    "    plt.subplot(3,30,i+1)\n",
    "    plt.imshow(gcam.fmap_pool['module.sc3_1'].cpu().numpy()[0][i])\n",
    "for i in range(30):\n",
    "    plt.subplot(3,30,i+1+30)\n",
    "    plt.imshow(gcam.fmap_pool['module.sc3_2'].cpu().numpy()[0][i])\n",
    "for i in range(30):\n",
    "    plt.subplot(3,30,i+1+60)\n",
    "    plt.imshow(gcam.fmap_pool['module.sc3_3'].cpu().numpy()[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "#print(gcam.fmap_pool['module.sc1_1'].cpu().numpy()[0][num])\n",
    "plt.figure(figsize=(16,5))\n",
    "for i in range(30):\n",
    "    plt.subplot(3,10,i+1)\n",
    "    plt.imshow(gcam.fmap_pool['module.rp1'].cpu().numpy()[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcam.fmap_pool['module.sc1_1'].cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "conv_list = ['module.sc1.conv1','module.sc1.conv2','module.sc1.conv3']\n",
    "conv_num = 0\n",
    "#print(gcam.fmap_pool[conv_list[conv_num]].cpu().numpy()[0][num])\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(gcam.fmap_pool[conv_list[conv_num]].cpu().numpy()[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "conv_list = ['module.sc1.conv1','module.sc1.conv2','module.sc1.conv3']\n",
    "conv_num = 1\n",
    "#print(gcam.fmap_pool[conv_list[conv_num]].cpu().numpy()[0][num])\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(gcam.fmap_pool[conv_list[conv_num]].cpu().numpy()[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 1\n",
    "conv_list = ['module.sc1.conv1','module.sc1.conv2','module.sc1.conv3']\n",
    "conv_num = 2\n",
    "#print(gcam.fmap_pool[conv_list[conv_num]].cpu().numpy()[0][num])\n",
    "for i in range(2):\n",
    "    plt.subplot(1,2,i+1)\n",
    "    plt.imshow(gcam.fmap_pool[conv_list[conv_num]].cpu().numpy()[0][i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.module.sc1.conv1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(model1.module.sc1.conv1.weight[0][i].cpu().detach().numpy())\n",
    "    plt.imshow(model1.module.sc1.conv1.weight[0][i].cpu().detach().numpy())#.shape\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(model1.module.sc1.conv2.weight[0][i].cpu().detach().numpy())\n",
    "    plt.imshow(model1.module.sc1.conv2.weight[0][i].cpu().detach().numpy())#.shape\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(model1.module.sc1.conv3.weight[0][i].cpu().detach().numpy())\n",
    "    plt.imshow(model1.module.sc1.conv3.weight[0][i].cpu().detach().numpy())#.shape\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SC_CNN_v0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
