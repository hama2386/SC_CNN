{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "SD8EvIMWEBPH",
    "outputId": "f582d519-eb7a-457f-9705-0d961fc032a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 22 07:06:00 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 61%   62C    P5    28W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 47%   59C    P0    71W / 250W |      0MiB / 11019MiB |      1%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  Off  | 00000000:86:00.0 Off |                  N/A |\n",
      "| 31%   41C    P0    55W / 250W |      0MiB / 11019MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 37%   55C    P0    29W / 250W |      0MiB / 11016MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import sys\\nsys.stdout = open('/dev/stdout', 'w')\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import sys\n",
    "sys.stdout = open('/dev/stdout', 'w')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_CNN.ipynb\r\n",
      "SC_CNN_v0.ipynb\r\n",
      "SC_CNN_v0.py\r\n",
      "SC_CNN_v0_deepSC_Ln_gradcam_jan21.ipynb\r\n",
      "SC_CNN_v0_deepSC_Ln_jan20.ipynb\r\n",
      "SC_CNN_v0_deepSC_Ln_jan21_nl1_test-Copy1.ipynb\r\n",
      "SC_CNN_v0_deepSC_Ln_jan21_nl1_test.ipynb\r\n",
      "Untitled.ipynb\r\n",
      "__pycache__\r\n",
      "class_acc_no_size.csv\r\n",
      "class_acc_sized.csv\r\n",
      "data\r\n",
      "data.tar.gz\r\n",
      "deepsc_nln_jan21.pt\r\n",
      "deepscln_jan20.pt\r\n",
      "elastic_test.ipynb\r\n",
      "ln_jan20_testresult.csv\r\n",
      "ln_jan20_testresult_9only.csv\r\n",
      "ln_jan20_testresult_nl1.csv\r\n",
      "ln_jan20_testresult_nl1_15-Copy1.csv\r\n",
      "ln_jan20_testresult_nl1_15.csv\r\n",
      "ln_jan20_testresult_nl1_30.csv\r\n",
      "mnist_4x\r\n",
      "mnist_4x.tar.gz\r\n",
      "mnist_png.tar\r\n",
      "mnist_sized\r\n",
      "mnist_sized.tar.gz\r\n",
      "mnist_sized_trans.ipynb\r\n",
      "nohup.out\r\n",
      "parallel.py\r\n",
      "sized_val\r\n",
      "sized_val.tar.gz\r\n",
      "test.csv\r\n",
      "total_acc_no_size.csv\r\n",
      "total_acc_sized.csv\r\n",
      "untitled.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndE45qny75h7"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bkbd3Z9yeGVL"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVOENNOie_qk"
   },
   "outputs": [],
   "source": [
    "#!tar -zxvf 'mnist_4x.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sn6W5p2EQcdy"
   },
   "outputs": [],
   "source": [
    "INTERNAL_DATA_PATH = 'mnist_4x/'\n",
    "INTERNAL_DATA_PATH_MAIN = 'mnist_4x/resized'\n",
    "INTERNAL_DATA_PATH_OTHER = 'mnist_4x/centered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuCAgoS1Hn4L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    " \n",
    "# Get a list of all files in directory\n",
    "for rootDir, subdirs, filenames in os.walk(INTERNAL_DATA_PATH):\n",
    "    # Find the files that matches the given patterm\n",
    "    for filename in fnmatch.filter(filenames, '.*'):\n",
    "        try:\n",
    "            #print(filename)\n",
    "            os.remove(os.path.join(rootDir, filename))\n",
    "        except OSError:\n",
    "            print(\"Error while deleting file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "Wdo5yu_g4iLs",
    "outputId": "3a21d03f-310c-4f9c-9d07-fa08ad62bb87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 909.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "for _ in tqdm(range(10)):\n",
    "    sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "g5aQe5lBNhO-",
    "outputId": "3660c43b-5f22-43eb-c34d-d912061581f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import cv2\\nimport os\\n\\nnew_path = ['data/ds6']#['data/ds1','data/ds2','data/ds3','data/ds4','data/ds5']\\nimg_size = [3]#[729,243,81,27,9]  \\n\\nfor l in range(1):\\n    os.mkdir(new_path[l])\\n    for i in os.listdir(INTERNAL_DATA_PATH_MAIN):\\n        os.mkdir(os.path.join(new_path[l],i))\\n        for j in os.listdir(os.path.join(INTERNAL_DATA_PATH_MAIN,i)):\\n            os.mkdir(os.path.join(new_path[l],i,j))\\n            for k in tqdm(os.listdir(os.path.join(INTERNAL_DATA_PATH_MAIN,i,j))):\\n                img_origin = cv2.imread(os.path.join(INTERNAL_DATA_PATH_MAIN,i,j,k))\\n                img_resized = cv2.resize(img_origin,(img_size[l],img_size[l]))\\n                cv2.imwrite(os.path.join(new_path[l],i,j,k),img_resized)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "import os\n",
    "\n",
    "new_path = ['data/ds6']#['data/ds1','data/ds2','data/ds3','data/ds4','data/ds5']\n",
    "img_size = [3]#[729,243,81,27,9]  \n",
    "\n",
    "for l in range(1):\n",
    "    os.mkdir(new_path[l])\n",
    "    for i in os.listdir(INTERNAL_DATA_PATH_MAIN):\n",
    "        os.mkdir(os.path.join(new_path[l],i))\n",
    "        for j in os.listdir(os.path.join(INTERNAL_DATA_PATH_MAIN,i)):\n",
    "            os.mkdir(os.path.join(new_path[l],i,j))\n",
    "            for k in tqdm(os.listdir(os.path.join(INTERNAL_DATA_PATH_MAIN,i,j))):\n",
    "                img_origin = cv2.imread(os.path.join(INTERNAL_DATA_PATH_MAIN,i,j,k))\n",
    "                img_resized = cv2.resize(img_origin,(img_size[l],img_size[l]))\n",
    "                cv2.imwrite(os.path.join(new_path[l],i,j,k),img_resized)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-52A9hHEf9y"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "########################################################################\n",
    "batch_size = 16\n",
    "########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uv0z7-vNFNS4"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#net = Net()\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    net = nn.DataParallel(net)\n",
    "#net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizedMnistDataset(Dataset):\n",
    "    def __init__(self,dir_list,transform=None):\n",
    "        self.dir_list = dir_list\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.dataset_list = []\n",
    "        for i in range(len(dir_list)):\n",
    "            temp_dataset = datasets.ImageFolder(root=self.dir_list[i],transform = self.transform)\n",
    "            self.dataset_list.append(temp_dataset)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset_list[0])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.dataset_list[0][idx],self.dataset_list[1][idx],self.dataset_list[2][idx],self.dataset_list[3][idx],self.dataset_list[4][idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/ds2/testing',\n",
       " 'data/ds3/testing',\n",
       " 'data/ds4/testing',\n",
       " 'data/ds5/testing',\n",
       " 'data/ds6/testing']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_path = ['data/ds2','data/ds3','data/ds4','data/ds5','data/ds6']\n",
    "\n",
    "train_dataset_path = [x+\"/training\" for x in new_path]\n",
    "test_dataset_path = [x+\"/testing\" for x in new_path]\n",
    "test_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = [729,243,81,27,9]  \n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainMnistDataset = SizedMnistDataset(train_dataset_path,transform)\n",
    "testMnistDataset = SizedMnistDataset(test_dataset_path,transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainMnistDataset,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle=True,\n",
    "                                         num_workers=8)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testMnistDataset,\n",
    "                                          batch_size = batch_size, \n",
    "                                          shuffle=False,\n",
    "                                        num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temptrainloader = torch.utils.data.DataLoader(temp_dataset,\\n                                          batch_size = 32, \\n                                          shuffle=True)\\nfor i,image in enumerate(temptrainloader):\\n    print(image[0].size())\\n    break'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''temptrainloader = torch.utils.data.DataLoader(temp_dataset,\n",
    "                                          batch_size = 32, \n",
    "                                          shuffle=True)\n",
    "for i,image in enumerate(temptrainloader):\n",
    "    print(image[0].size())\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imshow(image[0][0])\\nplt.show()\\nimshow(image[1][0])\\nplt.show()\\nimshow(image[2][0])\\nplt.show()\\nimshow(image[3][0])\\nplt.show()\\nimshow(image[4][0])\\nplt.show()'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "for j in range(10):\n",
    "    for i,image in tqdm(enumerate(trainloader)):\n",
    "        if(i==0):\n",
    "            print(image[0][0].size())\n",
    "            print(image[0][1])\n",
    "            print(image[1][1])\n",
    "            print(image[2][1])\n",
    "            print(image[3][1])\n",
    "            print(image[4][1])'''\n",
    "    \n",
    "'''imshow(image[0][0])\n",
    "plt.show()\n",
    "imshow(image[1][0])\n",
    "plt.show()\n",
    "imshow(image[2][0])\n",
    "plt.show()\n",
    "imshow(image[3][0])\n",
    "plt.show()\n",
    "imshow(image[4][0])\n",
    "plt.show()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ez0McqnuHEZy",
    "outputId": "90401c4e-c7a6-4723-aa91-6d7be9b1c123"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import matplotlib.pyplot as plt\\nimport numpy as np\\n\\n# 이미지를 보여주기 위한 함수\\n\\n\\ndef imshow(img):\\n    img = img / 2 + 0.5     # unnormalize\\n    npimg = img.numpy()\\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\\n\\n\\n# 학습용 이미지를 무작위로 가져오기\\ndataiter = iter(trainloader)\\nimages = dataiter.next()\\n\\nfor i,images in enumerate(trainloader):\\n    print(images[0].shape)\\n    imshow(images[0][0][0])\\n    plt.show()\\n    imshow(images[0][0][1])\\n    plt.show()\\n    imshow(images[0][0][2])\\n    plt.show()\\n    imshow(images[0][0][3])\\n    plt.show()\\n    imshow(images[0][0][4])\\n    plt.show()\\n    break\\n\\n# 이미지 보여주기\\nimshow(torchvision.utils.make_grid(images))\\n# 정답(label) 출력\\nprint(' '.join('%5s' % labels[j] for j in range(4)))\\nplt.show()\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 이미지를 보여주기 위한 함수\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# 학습용 이미지를 무작위로 가져오기\n",
    "dataiter = iter(trainloader)\n",
    "images = dataiter.next()\n",
    "\n",
    "for i,images in enumerate(trainloader):\n",
    "    print(images[0].shape)\n",
    "    imshow(images[0][0][0])\n",
    "    plt.show()\n",
    "    imshow(images[0][0][1])\n",
    "    plt.show()\n",
    "    imshow(images[0][0][2])\n",
    "    plt.show()\n",
    "    imshow(images[0][0][3])\n",
    "    plt.show()\n",
    "    imshow(images[0][0][4])\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "# 이미지 보여주기\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 정답(label) 출력\n",
    "print(' '.join('%5s' % labels[j] for j in range(4)))\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3xw8JRiG1hf"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SCModule(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,output_number):\n",
    "        super(SCModule, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.output_number = output_number\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 9, stride=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, 3, stride=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(self.out_channels)\n",
    "        if self.output_number == 3:\n",
    "            x_1_1 = self.conv1(x[0])\n",
    "            x_1_2 = self.conv1(x[1])\n",
    "            x_1_3 = self.conv1(x[2])\n",
    "            \n",
    "            x_2_1 = self.conv2(x[1])\n",
    "            x_2_2 = self.conv2(x[2])\n",
    "            x_2_3 = self.conv2(x[3])\n",
    "            \n",
    "            x_3_1 = self.conv3(x[2])\n",
    "            x_3_2 = self.conv3(x[3])\n",
    "            x_3_3 = self.conv3(x[4])\n",
    "            \n",
    "            o_1_1 = torch.stack([x_1_1,x_2_1,x_3_1])\n",
    "            o_1_1 = torch.sum(o_1_1,0)\n",
    "            \n",
    "            o_1_2 = torch.stack([F.conv2d(x[1], self.conv1.weight, bias=self.conv1.bias, stride=3, padding=4, dilation=1, groups=1),\n",
    "                                 F.conv2d(x[2], self.conv2.weight, bias=self.conv2.bias, stride=1, padding=1, dilation=1, groups=1)])\n",
    "            o_1_2 = torch.sum(o_1_2,0)\n",
    "            \n",
    "            o_1_3 = F.conv2d(x[2], self.conv1.weight, bias=self.conv1.bias, stride=1, padding=4, dilation=1, groups=1)\n",
    "            \n",
    "            o_2_1 = torch.stack([x_1_2,x_2_2,x_3_2])\n",
    "            o_2_1 = torch.sum(o_2_1,0)\n",
    "            \n",
    "            o_2_2 = torch.stack([F.conv2d(x[2], self.conv1.weight, bias=self.conv1.bias, stride=3, padding=4, dilation=1, groups=1),\n",
    "                                 F.conv2d(x[3], self.conv2.weight, bias=self.conv2.bias, stride=1, padding=1, dilation=1, groups=1)])\n",
    "            o_2_2 = torch.sum(o_2_2,0)\n",
    "            \n",
    "            o_2_3 = F.conv2d(x[3], self.conv1.weight, bias=self.conv1.bias, stride=1, padding=4, dilation=1, groups=1)\n",
    "            \n",
    "            o_3_1 = torch.stack([x_1_3,x_2_3,x_3_3])\n",
    "            o_3_1 = torch.sum(o_3_1,0)\n",
    "            \n",
    "            o_3_2 = torch.stack([F.conv2d(x[3], self.conv1.weight, bias=self.conv1.bias, stride=3, padding=4, dilation=1, groups=1),\n",
    "                                 F.conv2d(x[4], self.conv2.weight, bias=self.conv2.bias, stride=1, padding=1, dilation=1, groups=1)])\n",
    "            o_3_2 = torch.sum(o_3_2,0)\n",
    "            \n",
    "            o_3_3 = F.conv2d(x[4], self.conv1.weight, bias=self.conv1.bias, stride=1, padding=4, dilation=1, groups=1)\n",
    "            \n",
    "            return [torch.cat([o_1_1,o_1_2,o_1_3],dim=1),\n",
    "                    torch.cat([o_2_1,o_2_2,o_2_3],dim=1),\n",
    "                    torch.cat([o_3_1,o_3_2,o_3_3],dim=1)]\n",
    "    \n",
    "        if self.output_number == 1:\n",
    "            outputs = []\n",
    "            x_1_1 = self.conv1(x[0]) \n",
    "            x_1_2 = self.conv2(x[1]) \n",
    "            x_1_3 = self.conv3(x[2]) \n",
    "            #return [x_1_1,x_1_2,x_1_3]\n",
    "            x_1 = torch.stack([x_1_1,x_1_2,x_1_3])\n",
    "            x_1 = torch.sum(x_1,0)\n",
    "            #print(x_1.size())\n",
    "            #x_1 = torch.cat([x_1_1,x_1_2],dim=1)\n",
    "            outputs.append(x_1)\n",
    "            return outputs\n",
    "        \n",
    "            \n",
    "        '''outputs = []\n",
    "        for i in range(self.output_number):\n",
    "            x_1_1 = self.conv1(x[0+i]) \n",
    "            x_1_2 = self.conv2(x[1+i]) \n",
    "            x_1_3 = self.conv3(x[2+i]) \n",
    "            #return [x_1_1,x_1_2,x_1_3]\n",
    "            x_1 = torch.stack([x_1_1,x_1_2,x_1_3])\n",
    "            x_1 = torch.sum(x_1,0)\n",
    "            #print(x_1.size())\n",
    "            #x_1 = torch.cat([x_1_1,x_1_2],dim=1)\n",
    "            outputs.append(x_1)\n",
    "        return outputs'''\n",
    "    \n",
    "\n",
    "    \n",
    "#model = SCModule(3,6,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "WVlamFzsir1-",
    "outputId": "88e3ab6f-1f33-439a-baeb-ae62300b4c6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for i,(d1,d2,d3,d4,d5) in enumerate(zip(trainloader1,trainloader2,trainloader3,trainloader4,trainloader5)):\\n    print(d1[0][0].shape)\\n    imshow(d1[0][0])\\n    plt.show()\\n    imshow(d2[0][0])\\n    plt.show()\\n    imshow(d3[0][0])\\n    plt.show()\\n    imshow(d4[0][0])\\n    plt.show()\\n    imshow(d5[0][0])\\n    plt.show()\\n\\n    print(d1[0].shape)\\n\\n    o1,o2,o3 = model(d1[0],d2[0],d3[0],d4[0],d5[0])\\n\\n    print(o1.shape)\\n    break\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for i,(d1,d2,d3,d4,d5) in enumerate(zip(trainloader1,trainloader2,trainloader3,trainloader4,trainloader5)):\n",
    "    print(d1[0][0].shape)\n",
    "    imshow(d1[0][0])\n",
    "    plt.show()\n",
    "    imshow(d2[0][0])\n",
    "    plt.show()\n",
    "    imshow(d3[0][0])\n",
    "    plt.show()\n",
    "    imshow(d4[0][0])\n",
    "    plt.show()\n",
    "    imshow(d5[0][0])\n",
    "    plt.show()\n",
    "\n",
    "    print(d1[0].shape)\n",
    "\n",
    "    o1,o2,o3 = model(d1[0],d2[0],d3[0],d4[0],d5[0])\n",
    "\n",
    "    print(o1.shape)\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tensor = torch.tensor((), dtype=torch.float64,device='cuda')\\npad2_1 = tensor.new_zeros((32,16,729,729))#.to('cuda')\\npad2_1[:,:6,:,:].size()\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tensor = torch.tensor((), dtype=torch.float64,device='cuda')\n",
    "pad2_1 = tensor.new_zeros((32,16,729,729))#.to('cuda')\n",
    "pad2_1[:,:6,:,:].size()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3r33VtajV0m"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,batch_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.sc1 = SCModule(3,6,3) \n",
    "        self.bn1_1 = nn.BatchNorm2d(18)\n",
    "        self.bn1_2 = nn.BatchNorm2d(18)\n",
    "        self.bn1_3 = nn.BatchNorm2d(18)\n",
    "        self.sc2 = SCModule(18,10,3)\n",
    "        self.bn2_1 = nn.BatchNorm2d(30)\n",
    "        self.bn2_2 = nn.BatchNorm2d(30)\n",
    "        self.bn2_3 = nn.BatchNorm2d(30)\n",
    "        self.sc3 = SCModule(30,15,3)\n",
    "        self.bn3_1 = nn.BatchNorm2d(45)\n",
    "        self.bn3_2 = nn.BatchNorm2d(45)\n",
    "        self.bn3_3 = nn.BatchNorm2d(45)\n",
    "        self.sc4 = SCModule(45,20,3)\n",
    "        self.bn4_1 = nn.BatchNorm2d(60)\n",
    "        self.bn4_2 = nn.BatchNorm2d(60)\n",
    "        self.bn4_3 = nn.BatchNorm2d(60)\n",
    "        self.sc5 = SCModule(60,90,1)\n",
    "        self.bn5 = nn.BatchNorm2d(90)\n",
    "        #self.sc3 = SCModule(20,15,1)\n",
    "        #self.fc1_1 = nn.Linear(6*81*81,500)\n",
    "        #self.fc1_2 = nn.Linear(6*27*27,500)\n",
    "        #self.fc1_3 = nn.Linear(6*9*9,500)\n",
    "        \n",
    "        self.fc2 = nn.Linear(90*3*3,120)\n",
    "        #self.bnfc2 = nn.BatchNorm1d(120)\n",
    "        #self.fc2 = nn.Linear(1500,120)\n",
    "        self.fc3 = nn.Linear(120,84)\n",
    "        #self.bnfc3 = nn.BatchNorm1d(84)\n",
    "        self.fc4 = nn.Linear(84,10)\n",
    "        \n",
    "        tensor = torch.tensor((), dtype=torch.float)\n",
    " \n",
    "        self.pad1 = tensor.new_zeros((batch_size,60,243,243))#.to('cuda')\n",
    "        self.pad2 = tensor.new_zeros((batch_size,60,81,81))#.to('cuda')\n",
    "\n",
    "\n",
    "    def forward(self, i1,i2,i3,i4,i5):\n",
    "        self.pad1 = self.pad1.to(i1.device)\n",
    "        self.pad2 = self.pad2.to(i1.device)\n",
    "        x1_1,x1_2,x1_3 = self.sc1([i1,i2,i3,i4,i5])\n",
    "        #x1_2,x1_3 = self.sc1([i2,i3,i4,i5])\n",
    "        x1_1 = F.relu(self.bn1_1(x1_1))\n",
    "        x1_2 = F.relu(self.bn1_2(x1_2))\n",
    "        x1_3 = F.relu(self.bn1_3(x1_3))\n",
    "        \n",
    "        #print(x1_1)\n",
    "        #print(self.pad1)\n",
    "        bat_size = x1_1.size()[0]\n",
    "        chan_size = x1_1.size()[1]\n",
    "        x2_1,x2_2,x2_3 = self.sc2([self.pad1[:bat_size,:chan_size,:,:],self.pad2[:bat_size,:chan_size,:,:],x1_1,x1_2,x1_3])\n",
    "        #x1_2,x1_3 = self.sc1([i2,i3,i4,i5])\n",
    "        x2_1 = F.relu(self.bn2_1(x2_1))\n",
    "        x2_2 = F.relu(self.bn2_2(x2_2))\n",
    "        x2_3 = F.relu(self.bn2_3(x2_3))\n",
    "        \n",
    "        bat_size = x2_1.size()[0]\n",
    "        chan_size = x2_1.size()[1]\n",
    "        x3_1,x3_2,x3_3 = self.sc3([self.pad1[:bat_size,:chan_size,:,:],self.pad2[:bat_size,:chan_size,:,:],x2_1,x2_2,x2_3])\n",
    "        #x1_2,x1_3 = self.sc1([i2,i3,i4,i5])\n",
    "        x3_1 = F.relu(self.bn3_1(x3_1))\n",
    "        x3_2 = F.relu(self.bn3_2(x3_2))\n",
    "        x3_3 = F.relu(self.bn3_3(x3_3))\n",
    "        \n",
    "        bat_size = x3_1.size()[0]\n",
    "        chan_size = x3_1.size()[1]\n",
    "        x4_1,x4_2,x4_3 = self.sc4([self.pad1[:bat_size,:chan_size,:,:],self.pad2[:bat_size,:chan_size,:,:],x3_1,x3_2,x3_3])\n",
    "        #x1_2,x1_3 = self.sc1([i2,i3,i4,i5])\n",
    "        x4_1 = F.relu(self.bn4_1(x4_1))\n",
    "        x4_2 = F.relu(self.bn4_2(x4_2))\n",
    "        x4_3 = F.relu(self.bn4_3(x4_3))\n",
    "    \n",
    "        #print(x1_1.size())\n",
    "        \n",
    "        #x1_1 = x1_1.view(-1,6*81*81)\n",
    "        #x1_2 = x1_2.view(-1,6*27*27)\n",
    "        #x1_3 = x1_3.view(-1,6*9*9)\n",
    "        \n",
    "        #x1_1 = F.relu(self.fc1_1(x1_1))\n",
    "        #x1_2 = F.relu(self.fc1_2(x1_2))\n",
    "        #x1_3 = F.relu(self.fc1_3(x1_3))\n",
    "        \n",
    "        #x2 = torch.cat([x1_1,x1_2,x1_3],dim=1)\n",
    "        \n",
    "        x2 = self.sc5([x4_1,x4_2,x4_3])\n",
    "        x2 = F.relu(self.bn5(x2[0]))\n",
    "        \n",
    "        #print(x2.size())\n",
    "        \n",
    "        #print(x2_1.size())\n",
    "        \n",
    "        #print(x3.size())\n",
    "        \n",
    "        x2 = x2.view(-1, 90 * 3 * 3)\n",
    "        x2 = F.relu(self.fc2(x2))\n",
    "        x2 = F.relu(self.fc3(x2))\n",
    "        x2 = self.fc4(x2)\n",
    "        #print(x4.shape)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "xdajs104otKK",
    "outputId": "294463e8-ed55-49c4-939e-6bdda6c87d72"
   },
   "outputs": [],
   "source": [
    "from parallel import DataParallelModel,DataParallelCriterion\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.distributed as dist\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device_ids = [0,1]\n",
    "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "os.environ['MASTER_PORT'] = '29500'\n",
    "dist.init_process_group(backend='nccl',rank=0,world_size=1)\n",
    "model = Net(batch_size).to('cuda:0')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = DDP(model,device_ids = [0,1])\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74xBqeGcpub_"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = DataParallelCriterion(criterion,device_ids=[0,1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [00:01<00:00, 72.84it/s]\n"
     ]
    }
   ],
   "source": [
    "SIZED_VAL_PATH = 'sized_val'\n",
    "new_path = []\n",
    "for i in os.listdir('mnist_sized'):\n",
    "    #print(i)\n",
    "    temp = []\n",
    "    for j in range(1,6):\n",
    "        temp.append(os.path.join(SIZED_VAL_PATH,str(i),'ds'+str(j)))\n",
    "    new_path.append(temp)\n",
    "\n",
    "new_path.sort(key=lambda x:int(x[0].split('/')[1]))\n",
    "\n",
    "val_gen_arr = []\n",
    "for i in tqdm(range(0,len(new_path))):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    testMnistDataset = SizedMnistDataset(new_path[i],transform)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testMnistDataset,\n",
    "                                              batch_size = batch_size, \n",
    "                                              shuffle=False,\n",
    "                                            num_workers=8)\n",
    "    val_gen_arr.append(testloader)\n",
    "#\n",
    "#val_gen_arr\n",
    "accuracy = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Pd0stQ4Jolv7",
    "outputId": "3e1b592d-71a2-41cf-9936-8dd874e59431",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3750it [05:06, 12.25it/s]\n",
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of     0 : 100 %\n",
      "Accuracy of     1 : 96 %\n",
      "Accuracy of     2 : 99 %\n",
      "Accuracy of     3 : 99 %\n",
      "Accuracy of     4 : 100 %\n",
      "Accuracy of     5 : 100 %\n",
      "Accuracy of     6 : 99 %\n",
      "Accuracy of     7 : 99 %\n",
      "Accuracy of     8 : 100 %\n",
      "Accuracy of     9 : 98 %\n",
      "epoch: 1/30 | step: 10/3750 | trn loss: 0.8990 | val loss: 0.0403\n",
      "Accuracy of the network on the 10000 test images: 99 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/112 [00:02<05:21,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/112 [00:05<05:22,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 3/112 [00:08<05:18,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 4/112 [00:11<05:15,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 5/112 [00:14<05:11,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 6/112 [00:17<05:07,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 7/112 [00:20<05:04,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 8/112 [00:23<05:02,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 10 %\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "acc_list = []\n",
    "num_batches = len(trainloader)\n",
    "for epoch in range(30):\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    device = 'cuda:0'\n",
    "    for i,images in tqdm(enumerate(trainloader)):\n",
    "        #data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        c1 = images[0][0].to(device)\n",
    "        c2 = images[1][0].to(device)\n",
    "        c3 = images[2][0].to(device)\n",
    "        c4 = images[3][0].to(device)\n",
    "        c5 = images[4][0].to(device)\n",
    "        c6 = images[0][1].to(device)\n",
    "        #c61 = c6[:128].to('cuda:0')\n",
    "        #c62 = c6[128:].to('cuda:1')\n",
    "        output = model(c1,c2,c3,c4,c5)\n",
    "        #output = torch.nn.parallel.gather(output,'cuda:1')\n",
    "        loss = criterion(output, c6)\n",
    "        loss.backward()    # calc gradients\n",
    "        optimizer.step()   # update gradients\n",
    "        running_loss += loss.item()\n",
    "        #print(i)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad(): # very very very very important!!!\n",
    "        val_loss = 0.0\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for j,val in enumerate(testloader):\n",
    "            v1 = val[0][0].to(device)\n",
    "            v2 = val[1][0].to(device)\n",
    "            v3 = val[2][0].to(device)\n",
    "            v4 = val[3][0].to(device)\n",
    "            v5 = val[4][0].to(device)\n",
    "            val_labels = val[0][1].to(device)\n",
    "            val_output = model(v1,v2,v3,v4,v5)\n",
    "            v_loss = criterion(val_output, val_labels)\n",
    "            val_loss += v_loss\n",
    "            _, predicted = torch.max(val_output, 1)\n",
    "            c = (predicted == val_labels).squeeze()\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels).sum().item()\n",
    "            for i in range(len(val_labels)):\n",
    "                val_label = val_labels[i]\n",
    "                class_correct[val_label] += c[i].item()\n",
    "                class_total[val_label] += 1\n",
    "\n",
    "        for i in range(10):\n",
    "            if class_total[i]==0:\n",
    "                print('class_total = 0',class_correct,class_total)\n",
    "            else:\n",
    "                print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))\n",
    "\n",
    "    print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "        epoch+1, 30, i+1, num_batches, running_loss / 469, val_loss / len(testloader)\n",
    "    ))        \n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "    trn_loss_list.append(running_loss/1875)\n",
    "    val_loss_list.append(val_loss/len(testloader))\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    temp_acc = []\n",
    "    for testloader in tqdm(val_gen_arr):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "        with torch.no_grad():\n",
    "            for images in testloader:\n",
    "                c1 = images[0][0].to(device)\n",
    "                c2 = images[1][0].to(device)\n",
    "                c3 = images[2][0].to(device)\n",
    "                c4 = images[3][0].to(device)\n",
    "                c5 = images[4][0].to(device)\n",
    "                val_labels = images[0][1].to(device)\n",
    "                outputs = model(c1,c2,c3,c4,c5)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                c = (predicted == val_labels).squeeze()\n",
    "                total += val_labels.size(0)\n",
    "                correct += (predicted == val_labels).sum().item()\n",
    "        #print(total,correct,end='')\n",
    "\n",
    "        print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "        temp_acc.append(100 * correct / total)\n",
    "    acc_list.append(temp_acc)\n",
    "        \n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = open('ln_jan20_testresult_nl1_30.csv','w',newline=\"\")\n",
    "\n",
    "csvwriter = csv.writer(csvfile)\n",
    "for row in acc_list:\n",
    "    csvwriter.writerow(row)\n",
    "    \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(acc_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sc1.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2moJYh4OpSP6"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(testloader):\n",
    "        c1 = images[0][0].to(device)\n",
    "        c2 = images[1][0].to(device)\n",
    "        c3 = images[2][0].to(device)\n",
    "        c4 = images[3][0].to(device)\n",
    "        c5 = images[4][0].to(device)\n",
    "        labels = images[0][1].to(device)\n",
    "        outputs = model(c1,c2,c3,c4,c5)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(total,correct,end='')\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(testloader):\n",
    "        c1 = images[0][0].to(device)\n",
    "        c2 = images[1][0].to(device)\n",
    "        c3 = images[2][0].to(device)\n",
    "        c4 = images[3][0].to(device)\n",
    "        c5 = images[4][0].to(device)\n",
    "        labels = images[0][1].to(device)\n",
    "        outputs = model(c1,c2,c3,c4,c5)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZED_VAL_PATH = 'sized_val'\n",
    "\n",
    "new_path = []\n",
    "\n",
    "for i in os.listdir('mnist_sized'):\n",
    "    #print(i)\n",
    "    temp = []\n",
    "    for j in range(1,6):\n",
    "        temp.append(os.path.join(SIZED_VAL_PATH,str(i),'ds'+str(j)))\n",
    "    new_path.append(temp)\n",
    "\n",
    "#new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path.sort(key=lambda x:int(x[0].split('/')[1]))\n",
    "new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen_arr = []\n",
    "for i in tqdm(range(len(new_path))):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    testMnistDataset = SizedMnistDataset(new_path[i],transform)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testMnistDataset,\n",
    "                                              batch_size = batch_size, \n",
    "                                              shuffle=False,\n",
    "                                            num_workers=8,\n",
    "                                            pin_memory=True)\n",
    "    val_gen_arr.append(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_gen_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "\n",
    "for testloader in tqdm(val_gen_arr):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for images in testloader:\n",
    "            c1 = images[0][0].to(device)\n",
    "            c2 = images[1][0].to(device)\n",
    "            c3 = images[2][0].to(device)\n",
    "            c4 = images[3][0].to(device)\n",
    "            c5 = images[4][0].to(device)\n",
    "            val_labels = images[0][1].to(device)\n",
    "            outputs = model(c1,c2,c3,c4,c5)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            c = (predicted == val_labels).squeeze()\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels).sum().item()\n",
    "            for i in range(len(val_labels)):\n",
    "                val_label = val_labels[i]\n",
    "                class_correct[val_label] += c[i].item()\n",
    "                class_total[val_label] += 1\n",
    "\n",
    "        for i in range(10):\n",
    "            if class_total[i]==0:\n",
    "                print('class_total = 0',class_correct,class_total)\n",
    "            else:\n",
    "                print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))\n",
    "            #print(total,correct,end='')\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "    accuracy.append((100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(accuracy)):\n",
    "    print(i,accuracy[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(accuracy)):\n",
    "    print(accuracy[i],',',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'deepscln_jan20.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = open('test.csv','w',newline=\"\")\n",
    "\n",
    "csvwriter = csv.writer(csvfile)\n",
    "for row in [accuracy]:\n",
    "    csvwriter.writerow(row)\n",
    "    \n",
    "csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SC_CNN_v0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
