{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "SD8EvIMWEBPH",
    "outputId": "f582d519-eb7a-457f-9705-0d961fc032a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 10 01:37:06 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 206...  Off  | 00000000:08:00.0 Off |                  N/A |\r\n",
      "| 42%   45C    P0    47W / 175W |      0MiB /  7979MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce RTX 206...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n",
      "| 42%   46C    P0    19W / 175W |      0MiB /  7982MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import sys\\nsys.stdout = open('/dev/stdout', 'w')\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import sys\n",
    "sys.stdout = open('/dev/stdout', 'w')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC_CNN_v0.ipynb  data\t   mnist_4x.tar.gz  mnist_sized.tar.gz\r\n",
      "__pycache__\t mnist_4x  mnist_png.tar    parallel.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ndE45qny75h7"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bkbd3Z9yeGVL"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JVOENNOie_qk"
   },
   "outputs": [],
   "source": [
    "#!tar -zxvf 'mnist_4x.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sn6W5p2EQcdy"
   },
   "outputs": [],
   "source": [
    "INTERNAL_DATA_PATH = 'mnist_4x/'\n",
    "INTERNAL_DATA_PATH_MAIN = 'mnist_4x/resized'\n",
    "INTERNAL_DATA_PATH_OTHER = 'mnist_4x/centered'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuCAgoS1Hn4L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    " \n",
    "# Get a list of all files in directory\n",
    "for rootDir, subdirs, filenames in os.walk(INTERNAL_DATA_PATH):\n",
    "    # Find the files that matches the given patterm\n",
    "    for filename in fnmatch.filter(filenames, '.*'):\n",
    "        try:\n",
    "            #print(filename)\n",
    "            os.remove(os.path.join(rootDir, filename))\n",
    "        except OSError:\n",
    "            print(\"Error while deleting file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "Wdo5yu_g4iLs",
    "outputId": "3a21d03f-310c-4f9c-9d07-fa08ad62bb87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 932.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "for _ in tqdm(range(10)):\n",
    "    sleep(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "g5aQe5lBNhO-",
    "outputId": "3660c43b-5f22-43eb-c34d-d912061581f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import cv2\\nimport os\\n\\nnew_path = ['data/ds1','data/ds2','data/ds3','data/ds4','data/ds5']\\nimg_size = [729,243,81,27,9]  \\n\\nfor l in range(5):\\n    os.mkdir(new_path[l])\\n    for i in os.listdir(INTERNAL_DATA_PATH_MAIN):\\n        os.mkdir(os.path.join(new_path[l],i))\\n        for j in os.listdir(os.path.join(INTERNAL_DATA_PATH_MAIN,i)):\\n            os.mkdir(os.path.join(new_path[l],i,j))\\n            for k in tqdm(os.listdir(os.path.join(INTERNAL_DATA_PATH_MAIN,i,j))):\\n                img_origin = cv2.imread(os.path.join(INTERNAL_DATA_PATH_MAIN,i,j,k))\\n                img_resized = cv2.resize(img_origin,(img_size[l],img_size[l]))\\n                cv2.imwrite(os.path.join(new_path[l],i,j,k),img_resized)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import cv2\n",
    "import os\n",
    "\n",
    "new_path = ['data/ds1','data/ds2','data/ds3','data/ds4','data/ds5']\n",
    "img_size = [729,243,81,27,9]  \n",
    "\n",
    "for l in range(5):\n",
    "    os.mkdir(new_path[l])\n",
    "    for i in os.listdir(INTERNAL_DATA_PATH_MAIN):\n",
    "        os.mkdir(os.path.join(new_path[l],i))\n",
    "        for j in os.listdir(os.path.join(INTERNAL_DATA_PATH_MAIN,i)):\n",
    "            os.mkdir(os.path.join(new_path[l],i,j))\n",
    "            for k in tqdm(os.listdir(os.path.join(INTERNAL_DATA_PATH_MAIN,i,j))):\n",
    "                img_origin = cv2.imread(os.path.join(INTERNAL_DATA_PATH_MAIN,i,j,k))\n",
    "                img_resized = cv2.resize(img_origin,(img_size[l],img_size[l]))\n",
    "                cv2.imwrite(os.path.join(new_path[l],i,j,k),img_resized)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-52A9hHEf9y"
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uv0z7-vNFNS4"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#net = Net()\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    net = nn.DataParallel(net)\n",
    "#net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizedMnistDataset(Dataset):\n",
    "    def __init__(self,dir_list,transform=None):\n",
    "        self.dir_list = dir_list\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.dataset_list = []\n",
    "        for i in range(len(dir_list)):\n",
    "            temp_dataset = datasets.ImageFolder(root=self.dir_list[i],transform = self.transform)\n",
    "            self.dataset_list.append(temp_dataset)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset_list[0])\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.dataset_list[0][idx],self.dataset_list[1][idx],self.dataset_list[2][idx],self.dataset_list[3][idx],self.dataset_list[4][idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = ['data/ds1','data/ds2','data/ds3','data/ds4','data/ds5']\n",
    "\n",
    "train_dataset_path = [x+\"/training\" for x in new_path]\n",
    "test_dataset_path = [x+\"/testing\" for x in new_path]\n",
    "train_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = [729,243,81,27,9]  \n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainMnistDataset = SizedMnistDataset(train_dataset_path,transform)\n",
    "testMnistDataset = SizedMnistDataset(test_dataset_path,transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainMnistDataset,\n",
    "                                          batch_size = 256, \n",
    "                                          shuffle=True)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testMnistDataset,\n",
    "                                          batch_size = 256, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''temptrainloader = torch.utils.data.DataLoader(temp_dataset,\n",
    "                                          batch_size = 32, \n",
    "                                          shuffle=True)\n",
    "for i,image in enumerate(temptrainloader):\n",
    "    print(image[0].size())\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for i,image in enumerate(trainloader):\n",
    "    print(image[0][0].size())\n",
    "    print(image[0][1])\n",
    "    print(image[1][1])\n",
    "    print(image[2][1])\n",
    "    print(image[3][1])\n",
    "    print(image[4][1])\n",
    "    \n",
    "    imshow(images[0][0])\n",
    "    plt.show()\n",
    "    imshow(images[0][1])\n",
    "    plt.show()\n",
    "    imshow(images[0][2])\n",
    "    plt.show()\n",
    "    imshow(images[0][3])\n",
    "    plt.show()\n",
    "    imshow(images[0][4])\n",
    "    plt.show()\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ez0McqnuHEZy",
    "outputId": "90401c4e-c7a6-4723-aa91-6d7be9b1c123"
   },
   "outputs": [],
   "source": [
    "'''import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 이미지를 보여주기 위한 함수\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# 학습용 이미지를 무작위로 가져오기\n",
    "dataiter = iter(trainloader)\n",
    "images = dataiter.next()\n",
    "\n",
    "for i,images in enumerate(trainloader):\n",
    "    print(images[0].shape)\n",
    "    imshow(images[0][0][0])\n",
    "    plt.show()\n",
    "    imshow(images[0][0][1])\n",
    "    plt.show()\n",
    "    imshow(images[0][0][2])\n",
    "    plt.show()\n",
    "    imshow(images[0][0][3])\n",
    "    plt.show()\n",
    "    imshow(images[0][0][4])\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "# 이미지 보여주기\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 정답(label) 출력\n",
    "print(' '.join('%5s' % labels[j] for j in range(4)))\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3xw8JRiG1hf"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SCModule(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,output_number):\n",
    "        super(SCModule, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.output_number = output_number\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 9, stride=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, 3, stride=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''x_1_1 = self.conv1(x1) # 729->81\n",
    "        x_1_2 = self.conv2(x2) # 243->81\n",
    "        x_1_3 = self.conv3(x3) # 81->81\n",
    "        x_1 = torch.cat([x_1_1,x_1_2,x_1_3],dim=1)\n",
    "\n",
    "        x_2_1 = self.conv1(x2) # 243->27\n",
    "        x_2_2 = self.conv2(x3) # 81->27\n",
    "        x_2_3 = self.conv3(x4) # 27->27\n",
    "        x_2 = torch.cat([x_2_1,x_2_2,x_2_3],dim=1)\n",
    "\n",
    "        x_3_1 = self.conv1(x3) # 81->9\n",
    "        x_3_2 = self.conv2(x4) # 27->9\n",
    "        x_3_3 = self.conv3(x5) # 9->9\n",
    "        x_3 = torch.cat([x_3_1,x_3_2,x_3_3],dim=1)'''\n",
    "        outputs = []\n",
    "        for i in range(self.output_number):\n",
    "            x_1_1 = self.conv1(x[0+i]) \n",
    "            x_1_2 = self.conv2(x[1+i]) \n",
    "            x_1_3 = self.conv3(x[2+i]) \n",
    "            x_1 = torch.cat([x_1_1,x_1_2,x_1_3],dim=1)\n",
    "            outputs.append(x_1)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "    \n",
    "#model = SCModule(3,6,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "WVlamFzsir1-",
    "outputId": "88e3ab6f-1f33-439a-baeb-ae62300b4c6c"
   },
   "outputs": [],
   "source": [
    "'''for i,(d1,d2,d3,d4,d5) in enumerate(zip(trainloader1,trainloader2,trainloader3,trainloader4,trainloader5)):\n",
    "    print(d1[0][0].shape)\n",
    "    imshow(d1[0][0])\n",
    "    plt.show()\n",
    "    imshow(d2[0][0])\n",
    "    plt.show()\n",
    "    imshow(d3[0][0])\n",
    "    plt.show()\n",
    "    imshow(d4[0][0])\n",
    "    plt.show()\n",
    "    imshow(d5[0][0])\n",
    "    plt.show()\n",
    "\n",
    "    print(d1[0].shape)\n",
    "\n",
    "    o1,o2,o3 = model(d1[0],d2[0],d3[0],d4[0],d5[0])\n",
    "\n",
    "    print(o1.shape)\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3r33VtajV0m"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.sc1 = SCModule(3,3,3) \n",
    "        self.sc2 = SCModule(9,5,1)\n",
    "        self.fc2 = nn.Linear(15*9*9,120)\n",
    "        self.fc3 = nn.Linear(120,84)\n",
    "        self.fc4 = nn.Linear(84,10)\n",
    "\n",
    "\n",
    "    def forward(self, i1,i2,i3,i4,i5):\n",
    "        x1_1,x1_2,x1_3 = self.sc1([i1,i2,i3,i4,i5])\n",
    "        x1_1 = F.relu(x1_1)\n",
    "        x1_2 = F.relu(x1_2)\n",
    "        x1_3 = F.relu(x1_3)\n",
    "        \n",
    "        x2 = self.sc2([x1_1,x1_2,x1_3])\n",
    "        x2 = F.relu(x2[0])\n",
    "        #print(x2.shape)\n",
    "        \n",
    "        x2 = x2.view(-1, 15 * 9 * 9)\n",
    "        x2 = F.relu(self.fc2(x2))\n",
    "        x2 = F.relu(self.fc3(x2))\n",
    "        x2 = F.softmax(self.fc4(x2),dim=1)\n",
    "        #print(x4.shape)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "xdajs104otKK",
    "outputId": "294463e8-ed55-49c4-939e-6bdda6c87d72"
   },
   "outputs": [],
   "source": [
    "from parallel import DataParallelModel,DataParallelCriterion\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Net()\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74xBqeGcpub_"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = DataParallelCriterion(criterion,device_ids=[0,1])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Pd0stQ4Jolv7",
    "outputId": "3e1b592d-71a2-41cf-9936-8dd874e59431"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "num_batches = len(trainloader)\n",
    "for epoch in range(15):\n",
    "    running_loss = 0.0\n",
    "    for i,images in tqdm(enumerate(trainloader)):\n",
    "        #data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        c1 = images[0][0].to(device)\n",
    "        c2 = images[1][0].to(device)\n",
    "        c3 = images[2][0].to(device)\n",
    "        c4 = images[3][0].to(device)\n",
    "        c5 = images[4][0].to(device)\n",
    "        c6 = images[0][1].to(device)\n",
    "        #c61 = c6[:128].to('cuda:0')\n",
    "        #c62 = c6[128:].to('cuda:1')\n",
    "        output = model(c1,c2,c3,c4,c5)\n",
    "        loss = criterion(output, c6)\n",
    "        loss.backward()    # calc gradients\n",
    "        optimizer.step()   # update gradients\n",
    "        running_loss += loss.item()\n",
    "        #print(i)\n",
    "        #if (i+1) % 50 == 0:    # print every 2000 mini-batches\n",
    "        \n",
    "    with torch.no_grad(): # very very very very important!!!\n",
    "        val_loss = 0.0\n",
    "        for j,val in enumerate(testloader):\n",
    "            v1 = val[0][0].to(device)\n",
    "            v2 = val[1][0].to(device)\n",
    "            v3 = val[2][0].to(device)\n",
    "            v4 = val[3][0].to(device)\n",
    "            v5 = val[4][0].to(device)\n",
    "            val_labels = val[0][1].to(device)\n",
    "            val_output = model(v1,v2,v3,v4,v5)\n",
    "            v_loss = criterion(val_output, val_labels)\n",
    "            val_loss += v_loss\n",
    "\n",
    "    print(\"epoch: {}/{} | step: {}/{} | trn loss: {:.4f} | val loss: {:.4f}\".format(\n",
    "        epoch+1, 15, i+1, num_batches, running_loss / 235, val_loss / len(testloader)\n",
    "    ))            \n",
    "\n",
    "    trn_loss_list.append(running_loss/235)\n",
    "    val_loss_list.append(val_loss/len(testloader))\n",
    "    running_loss = 0.0\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2moJYh4OpSP6"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(testloader):\n",
    "        c1 = images[0][0].to(device)\n",
    "        c2 = images[1][0].to(device)\n",
    "        c3 = images[2][0].to(device)\n",
    "        c4 = images[3][0].to(device)\n",
    "        c5 = images[4][0].to(device)\n",
    "        labels = images[0][1].to(device)\n",
    "        outputs = model(c1,c2,c3,c4,c5)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print(total,correct,end='')\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(testloader):\n",
    "        c1 = images[0][0].to(device)\n",
    "        c2 = images[1][0].to(device)\n",
    "        c3 = images[2][0].to(device)\n",
    "        c4 = images[3][0].to(device)\n",
    "        c5 = images[4][0].to(device)\n",
    "        labels = images[0][1].to(device)\n",
    "        outputs = model(c1,c2,c3,c4,c5)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SC_CNN_v0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
